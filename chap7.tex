\chapter{Conclusion and Future Work}
\label{chap:conclusion}

\section{Conclusion}
\label{sec:conclusion}

In accordance to \Cref{chap:introduction}, the primary goal of this dissertation has been to design a system that effectively summarises typical usages of a target API. We firstly described the problem faced in the current dissertation, in \Cref{sec:problem-definition}, where we moreover presented four main features that a system that performs API usage mining should exhibit. After that, we analysed our approach to the problem, in \Cref{chap:conceptual-design-work}. There, we justified any design decisions on which we proceeded, while we also identified the decisions that would probably impact the results of the system, and which should be evaluated in the evaluation process. Then, in \Cref{chap:implementation}, we extensively analysed the actual implementation of the system, by providing an overview of the system's architecture, and describing the functionality of each component in its own section. Furthermore, in the same chapter, we analysed the algorithms that have been implemented and/or used by the system.

Taking into account that there were several design decisions that could impact the results of the system, we decided to evaluate five different versions of the system, by conducting experiments where, a pair of different versions each time, would evaluate a clear hypothesis. Hence, in \Cref{chap:evaluation}, we clearly defined five different hypotheses, with the first four of them being related to the different algorithms that have been implemented, and the last one being the key hypothesis of the current dissertation, which is that the presentation of snippets would be of more value to the developers than that of API call sequences. The outcomes of the first four experiments were really interesting, showing the efficiency of the novel summarisation algorithm we implemented, as well as any possible differences between the various clustering techniques that we leveraged. In addition to that, the last experiment evidently revealed that the key hypothesis is confirmed by the system. Moreover, we believe that the indicative mined snippets of the system, presented in the appendices, are concise, readable, precise, and cover several usages of the target API. This means that they could be efficiently used for documentation purposes.

It should be now clear that the system we implemented exhibits the four features described in \Cref{sec:problem-definition}. More specifically, it clusters similar usage examples, by taking into account their API calls, while it also takes into consideration their structure at a later stage. Furthermore, the summarisation algorithm ensures concise and readable snippets, which are presented to the users as a ranked list, that indicates their popularity.


\section{Future Work}
\label{sec:future-work}

Although we have tried several different techniques in the different components that have been implemented, including for instance various sequence similarity metrics, and clustering techniques, there are still several lines of improvement in the system. Most of them, however, have to do with the approach followed on each step of the implementation. In this section, we describe a number of possible enhancements, that are either related to the limitations of the system, or even to the decisions made on each step.

We believe that the most important component to be integrated to the system is the parser, that would enable the extraction of the \texttt{.arff} file without the need to provide this as an input. This would also facilitate possible further evaluation of the system, using additional libraries. We clearly justified the decision to avoid implementing this component in this dissertation, in \Cref{subsec:input-form}.

Regarding the clustering techniques used in the implementation, it would be convenient enough to be able to predict the number of clusters for the $k$-medoids algorithm. Although, as explained in \Cref{subsec:clustering-techniques}, this could not be easily achieved using popular techniques used for this task, we could probably try to define a metric such as the one used in \cite{Wang:2013}, where \nolink{\citeauthor{Wang:2013}} define a dissimilarity metric between the mined usage patterns. In a similar manner, we could either make use of a sequence similarity metric, to compute the dissimilarity between the mined sequences, or even better of a tree edit distance metric, in order to compute the dissimilarity between the mined snippets. Then, we could restart the clustering process using a different $k$ value, until achieving the highest possible dissimilarity between the mined snippets.

In addition to the aforementioned improvements, we could also extend the approach used to retrieve the top mined sequences from each cluster. That it, instead of retrieving a fixed number of sequences from each cluster, we could use a two-stage clustering approach where, after clustering based on the API call sequences of the snippets, we could further cluster the results of the formed clusters, using a tree edit distance metric. This would enable the retrieval of snippets that use the same API call sequence, but which differ in their structure.

Finally, a future work could definitely include the use of additional datasets, as well as the comparison of our system with that presented in \cite{Buse:2012}. The reason why we did not proceeded to such a comparison is that the version of this system that is available (a) does not support snippets that use features introduced in Java 1.8, and (b) there is additional misbehaviour of the system when outputting the mined snippets. Our attempt to fix these issues did not lead to a stable version of the system. Thus, the only way to retrieve its mined snippets is by manually proceeding to some cleaning, for which we would have to spent valuable time.
